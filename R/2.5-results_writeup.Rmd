---
title: "Automation Failures in ATC: Standard Results"
author: "ljgs"
date: "20/11/2019"
output:
  word_document: default
  html_document: default
  pdf_document: default
---
by Luke Strickland

```{r load_packages_and_data, echo= FALSE , results = "hide", message=FALSE, warning=FALSE}


library(dplyr)
library(tidyr)
library(ggplot2)
library(lme4)
library(car)
library(lsmeans)
library(pander)
options(digits=2)
source("R/0-analysis_functions.R")

load("img/cleandats.RData")

cleandats <- cleandats %>% mutate(C = toupper(S)==R)

colnames(cleandats)[colnames(cleandats)=="sess"] <- "Session"
colnames(cleandats)[colnames(cleandats)=="cond"] <- "Condition"
colnames(cleandats)[colnames(cleandats)=="S"] <- "Stimulus"
colnames(cleandats)[colnames(cleandats)=="failtrial"] <- "Automation"

cleandats$Session <- factor(cleandats$Session, levels=c("1", "2"),
                      labels=c("One", "Two"))

cleandats$Condition <- factor(cleandats$Condition , levels=c("AUTO", "MANUAL"),
                      labels=c("Automation", "Manual"))

cleandats$Automation <- factor(cleandats$Automation, levels=c("nonf", "fail"),
                      labels=c("Automation Success", "Automation Failure"))

cleandats$Stimulus <- factor(cleandats$Stimulus, levels=c("c", "n"),
                      labels=c("Conflict", "Non-conflict"))

theme_set(theme_simple())

accs <-
  cleandats %>% group_by(s, Stimulus, Condition, Automation, Session) %>% 
  filter(!is.na(R)) %>% summarise(acc = mean(C)) %>%
  arrange(s) %>% arrange(Automation)

RTs <- cleandats %>% group_by(s, Stimulus, Condition, Automation, Session) %>% 
  filter(C) %>% 
  summarise(RT=mean(RT))%>% arrange(Automation)


```

```{r accuracy_descriptives_fortext, echo= FALSE, message=FALSE, warning=FALSE}
#Descriptives for text chunks
S <- accs %>% group_by(Stimulus) %>% summarise(mean(acc))
S_se <- se2(accs, facs="Stimulus", dvnam="acc")

sess <- accs %>% group_by(Session) %>% summarise(mean(acc))
sess_se <- se2(accs, facs="Session", dvnam="acc")

cond_auto <- accs %>% group_by(Condition, Automation) %>% summarise(mean(acc))
cond_auto_se <- arr2df(
  se2(accs, facs=c("Condition", "Automation"), dvnam="acc"))


```


##### Accuracy
Participant accuracies are displayed in Figure 2. There were main effects of stimulus type, session, condition, and automation accuracy. Responses were more accurate to conflict trials 
(*M* = `r S[S$Stimulus=="Conflict",2]`, *SE* = `r S_se["Conflict"]`)
than to non-conflict trials
(*M* = `r S[S$Stimulus=="Non-conflict",2]`, *SE* = `r S_se["Non-conflict"]`).
Accuracy was lower on session one
(*M* = `r sess[sess$Session=="One",2]`, *SE* = `r sess_se["One"]`)
than on session two
(*M* = `r sess[sess$Session=="Two",2]`, *SE* = `r sess_se["Two"]`)
. The effects of automation condition and automation accuracy interacted. Participant accuracy was higher for trials where participants were provided correct automation (*M* = `r cond_auto[cond_auto$Condition=="Automation" & cond_auto$Automation=="Automation Success",3]`, 
*SE* = `r cond_auto_se[cond_auto_se$Condition=="Automation" & cond_auto_se$Automation=="Automation Success",3]`) than for corresponding manual trials (*M* = `r cond_auto[cond_auto$Condition=="Manual" & cond_auto$Automation=="Automation Success",3]`, 
*SE* = `r cond_auto_se[cond_auto_se$Condition=="Manual" & cond_auto_se$Automation=="Automation Failure",3]`), and lower when participants were provided incorrect automation (*M* = `r cond_auto[cond_auto$Condition=="Automation" & cond_auto$Automation=="Automation Failure",3]`, 
*SE* = `r cond_auto_se[cond_auto_se$Condition=="Manual" & cond_auto_se$Automation=="Automation Failure",3]`), as compared with matched manual trials (*M* = `r cond_auto[cond_auto$Condition=="Manual" & cond_auto$Automation=="Automation Failure",3]`, 
*SE* = `r cond_auto_se[cond_auto_se$Condition=="Manual" & cond_auto_se$Automation=="Automation Failure",3]`). These results suggest that participants did use the automation to their advantage, but on trials where the automation failed, it imposed a substantial cost to their accuracy. However, importantly, accuracy on automation incorrect trials was far from floor, suggesting that participants did not rely on the automation entirely.


```{r echo= FALSE}
acc_cap <- "*Figure 5.* Accuracies. Each panel corresponds to one stimulus type, on one experimental session. The error bars included
were calculated using the Morey (2008) bias-corrected method for within-subjects error bars."
```


```{r response_accuracy_graph, echo= FALSE, message=FALSE, warning=FALSE,fig.height = 8, fig.width = 13,fig.cap=acc_cap}
mean_accs <- accs %>% group_by(Stimulus, Condition, Automation, Session) %>%
  summarise(meanacc=mean(acc))

searr= se2(accs, facs= c("Stimulus", "Condition", "Automation", "Session"),
dvnam="acc", sfac="s")
se_accs <- as.data.frame.table(searr)
colnames(se_accs)[colnames(se_accs)=="Freq"] <- "seacc"

plot.df <- full_join(mean_accs, se_accs)

ggplot(plot.df, aes(Automation, meanacc)) +geom_point(aes(col=Condition, shape=Condition), size=3)  + 
  facet_grid(Session~Stimulus) + geom_errorbar(aes(
    ymax = meanacc + seacc,
    ymin = meanacc - seacc,
    colour = Condition
  )) +ylab ("Accuracy") +xlab("") +
    theme(text = element_text(size = 22))

```


```{r RT_descriptives_fortext, echo= FALSE, message=FALSE, warning=FALSE}
#Descriptives for text chunks
S_RT <- RTs %>% group_by(Stimulus) %>% summarise(mean(RT))
S_se_RT <- se2(RTs, facs="Stimulus", dvnam="RT")

sess_cond_RT <- RTs %>% group_by(Session, Condition) %>% summarise(mean(RT))
sess_cond_se_RT <- se2(RTs, facs=c("Session", "Condition"), 
                    dvnam="RT")

cond_auto_RT <- RTs %>% group_by(Condition, Automation) %>% summarise(mean(RT))
cond_auto_se_RT <- arr2df(
  se2(RTs, facs=c("Condition", "Automation"), dvnam="RT"))



```


##### Response Times
Mean correct RTs are displayed in Figure 3. There were main effects of stimulus type, session, 
condition, and automation success. Correct responses were slower to conflict trials
(*M* = `r S_RT[S_RT$Stimulus=="Conflict",2]`, *SE* = `r S_se_RT["Conflict"]`)
than to non-conflict trials
(*M* = `r S_RT[S_RT$Stimulus=="Non-conflict",2]`, *SE* = `r S_se_RT["Non-conflict"]`). Crucially, as displayed in Table 3, the effects of 
condition and automation success interacted. On trials where 
the automation was successful, correct RTs were not subsantially different across
manual and automated conditions. By contrast, correct RTs 
were substantially slower on trials where automation failed,
as compared with matched manual trials.

The effects of condition and session interacted. On session 1,
RTs were slower in the automation condition
(*M* = `r sess_cond_RT %>% filter(Session=='One' & Condition=='Automation') %>% 
pull('mean(RT)')`,
*SE* = `r sess_cond_se_RT["One", "Automation"]`)
than in the manual condition
(*M* = `r sess_cond_RT %>% filter(Session=='One' & Condition=='Manual') %>% 
pull('mean(RT)')`,
*SE* = `r sess_cond_se_RT["One", "Manual"]`)
.
On session two, 
RTs were less substantially slower in the automation condition
(*M* = `r sess_cond_RT %>% filter(Session=='Two' & Condition=='Automation') %>% 
pull('mean(RT)')`,
*SE* = `r sess_cond_se_RT["Two", "Automation"]`)
than in the manual condition
(*M* = `r sess_cond_RT %>% filter(Session=='Two' & Condition=='Manual') %>% 
pull('mean(RT)')`,
*SE* = `r sess_cond_se_RT["Two", "Manual"]`), 
with the difference failing to cross the p <.005 threshold.
Follow up comparisons of the (non-significant) three way interaction 
of between session, condition and automation success (supplementary materials) indicate that differences
in RTs on successful automation trials decreased over days,
but differences between failure trials and matched manual trials remained. 


```{r echo= FALSE}
RT_cap <- "*Figure 4.* Correct Response Times (RTs). Each panel corresponds to responses to one typer of stimulus on one experimental session. The error bars included were calculated using the Morey (2008) bias-corrected method for within-subjects error bars."
```


```{r response_RT_graph 1, echo= FALSE, message=FALSE, warning=FALSE,fig.height = 4, fig.width = 13,fig.cap=RT_cap}
mean_RTs <- RTs %>% group_by(Stimulus, Condition, Automation,Session) %>% summarise(meanRT=mean(RT))

searr= se2(RTs, facs= c("Stimulus", "Condition", "Automation", "Session"), dvnam="RT", sfac="s")
se_RTs <- as.data.frame.table(searr)
colnames(se_RTs)[colnames(se_RTs)=="Freq"] <- "seRT"



plot.df <- full_join(mean_RTs, se_RTs)

ggplot(plot.df, aes(Automation, meanRT)) +geom_point(aes(col=Condition), size=3)  + 
  geom_line(aes(y=meanRT, group=interaction(Condition, Stimulus), col=Condition), linetype=2)+ ylab("Mean RT")+
  facet_grid(Session~Stimulus) + geom_errorbar(aes(
    ymax = meanRT + seRT,
    ymin = meanRT - seRT,
    colour = Condition
  ))
```

Table 3

*Correct Response Times. Displaying M(SE), with SEs calculated by the Morey (2008) bias-corrected method.*
```{r RT_table, echo= FALSE, message=FALSE, warning=TRUE, results='asis'}

tmp <- full_join(
  cond_auto_RT, cond_auto_se_RT)

tmp[,3] <- round(tmp[,3], 2)
tmp[,4] <- round(tmp[,4], 2)

MSEs<- paste(do.call(paste, c(tmp[,c(3, 4)], sep=" (")),
      ")", sep="")

cond_auto_RT_table <- cbind(as.data.frame(tmp[,1:2]), MSEs)

pandoc.table(
  cond_auto_RT_table %>% pivot_wider(names_from = c(Automation),
                            values_from = MSEs)
)

```

# Error RTs

```{r RT_table_e, echo= FALSE, message=FALSE, warning=TRUE, results='asis'}

RTse <- cleandats %>% group_by(s, Stimulus, Condition, Automation, Session) %>% 
  filter(!C) %>% 
  summarise(RT=mean(RT))%>% arrange(Automation)

cond_auto_RTe <- RTse %>% group_by(Condition, Automation) %>% summarise(mean(RT))
cond_auto_se_RTe <- arr2df(
  se2(RTs, facs=c("Condition", "Automation"), dvnam="RT"))


tmp <- full_join(
  cond_auto_RTe, cond_auto_se_RTe)

tmp[,3] <- round(tmp[,3], 2)
tmp[,4] <- round(tmp[,4], 2)

MSEs<- paste(do.call(paste, c(tmp[,c(3, 4)], sep=" (")),
      ")", sep="")

cond_auto_RTe_table <- cbind(as.data.frame(tmp[,1:2]), MSEs)

pandoc.table(
  cond_auto_RTe_table %>% pivot_wider(names_from = c(Automation),
                            values_from = MSEs)
)

```



```{r, echo= FALSE, include=FALSE}

specialdats <- cleandats
specialdats$subjsesh <- interaction(cleandats$s, cleandats$Session)

accs <-
  specialdats %>% group_by(s, Condition, Automation) %>% 
  filter(!is.na(R)) %>% summarise(acc = mean(C)) %>%
  arrange(s) %>% arrange(Automation)


accs_success_effect <- accs %>% group_by(s) %>% 
  summarise(accboost = acc[Condition=="Automation" & Automation=="Automation Success"]-
              acc[Condition=="Manual"& Automation=="Automation Success"])


accs_failure_effect <- accs %>% group_by(s) %>% 
  summarise(accboost = acc[Condition=="Manual" & Automation=="Automation Failure"]-
              acc[Condition=="Automation"& Automation=="Automation Failure"])


mRTs <-
  specialdats %>% group_by(s, Condition, Automation) %>% 
  filter(!is.na(R)) %>% summarise(mRT = mean(RT[C])) %>%
  arrange(s) %>% arrange(Automation)



mRTs_failure_effect <- mRTs %>% group_by(s) %>% 
  summarise(mRTboost = mRT[Condition=="Automation"& Automation=="Automation Failure"] - 
              mRT[Condition=="Manual" & Automation=="Automation Failure"]
              )

cor(mRTs_failure_effect$mRTboost, accs_failure_effect$accboost)
cor.test(mRTs_failure_effect$mRTboost, accs_success_effect$accboost)


accs_success_effect$accdrop <- accs_failure_effect$accboost
accs_success_effect$RTcost <- mRTs_failure_effect$mRTboost

fit_failsuccess <- lm(accdrop~accboost, data=accs_success_effect)
fit_failRT <- lm(accdrop~RTcost, data=accs_success_effect)
fit_successRT <- lm(accboost~RTcost, data=accs_success_effect)

theme_set(theme_classic())

ggplot(accs_success_effect, aes(x=accboost, y=accdrop)) + geom_point() + 
   ylab("Failure cost") + xlab("Success improvement") +
  geom_abline(slope=fit_failsuccess$coefficients[2], intercept=fit_failsuccess$coefficients[1], linetype=2)

ggplot(accs_success_effect, aes(x=RTcost, y=accboost)) + geom_point() + 
   ylab("Success improvement") + xlab( "RT cost on failure trials") +
  geom_abline(slope=fit_successRT$coefficients[2], intercept=fit_successRT$coefficients[1], linetype=2)

 ggplot(accs_success_effect, aes(x=RTcost, y=accdrop)) + geom_point() + 
   ylab("Failure cost") + xlab( "RT cost on failure trials") +
  geom_abline(slope=fit_failRT $coefficients[2], intercept=fit_failRT $coefficients[1], linetype=2)
 

 users <- accs_success_effect %>%
   filter(accboost>0.05|accdrop>0.05) %>% .$s

save(users, file="img/users.RData")
```

```{r, echo= FALSE, include=FALSE}
 
library(readxl) 
questionnaires <- read_xlsx("auto_trust_qs.xlsx")
qs <- cbind(questionnaires$pid, rowMeans(questionnaires[2:7]))
colnames(qs) <- c("s", "rel")

qs<-as.data.frame(qs)
qs$s <- as.character(qs$s)


tmp <- full_join(as.data.frame(qs), accs_success_effect, by="s")

cor_rel_accboost <- cor.test(tmp$rel, tmp$accboost)
cor_rel_accdrop <-cor.test(tmp$rel, tmp$accdrop)
 
```

We averaged the automation reliability scale across all questions for each participant.
The mean reliability score was `r mean(qs$rel)` (SD = `r sd(qs$rel)`). Reliablity scores
did not correlate with boosts in automation accuracy on successful automation trials, *r* (`r cor_rel_accboost$parameter`)= 
`r cor_rel_accboost$estimate`, *p* = `r cor_rel_accboost$p.value`
or drops in accuracy on automation incorrect trials *r* (`r cor_rel_accdrop$parameter`)= 
`r cor_rel_accdrop$estimate`, *p* = `r cor_rel_accdrop$p.value`.



<!-- # Acc effects individual differences -->

```{r acc_effects_ids, echo= FALSE, include=FALSE, message=FALSE, warning=TRUE, results='asis'}
acceff<- cleandats %>% group_by(s) %>% summarise(acc=mean(C[Condition=="Automation"]) - mean(C[Condition=="Manual"]), manacc=mean(C[Condition=="Manual"]), autacc=mean(C[Condition=="Automation"])) 


acceff %>% ggplot(aes(x=acc)) + geom_histogram()

acceff %>% ggplot(aes(x=manacc, y=acc)) + geom_point() +ylab("Automation Benefit") +
  geom_line(aes(y=0), linetype=2) + geom_line(aes(y=0.05), linetype=2) 

cor(acceff$acc, acceff$manacc)

acceff %>% ggplot(aes(x=autacc, y=acc)) + geom_point()


```


